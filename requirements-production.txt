# Production Requirements (CPU-only, API serving)
# For bulk processing, use backend/requirements.txt on local machine with GPU

# Core API dependencies
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6
aiofiles==23.2.1

# Database
psycopg2-binary>=2.9.9
sqlalchemy>=2.0.07
alembic>=1.13.0
python-dotenv==1.0.0

# Embeddings for semantic search (CPU-only is fine)
sentence-transformers==2.2.2
torch>=2.2.0,<2.9.0  # CPU version automatically installed
transformers==4.33.2

# Utilities
numpy>=1.24.3,<2.0.0
tqdm==4.66.1
isodate==0.6.1

# Note: The following are NOT needed in production (ingestion done locally):
# - whisperx (GPU-intensive transcription)
# - pyannote.audio (GPU-intensive speaker diarization)
# - librosa (audio processing for ingestion)
# - faster-whisper (GPU-intensive ASR)
# - yt-dlp (video downloading for ingestion)
#
# These dependencies are only needed on local machine for bulk processing.
# Production only serves API requests using pre-computed embeddings.
