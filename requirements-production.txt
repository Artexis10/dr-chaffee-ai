# Production Requirements (CPU-only)
# Supports both API serving AND lightweight incremental ingestion

# Core API dependencies
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6
aiofiles==23.2.1

# Database
psycopg2-binary>=2.9.9
sqlalchemy>=2.0.07
alembic>=1.13.0
python-dotenv==1.0.0

# Embeddings for semantic search (CPU-only is fine)
sentence-transformers==2.2.2
torch>=2.2.0,<2.9.0  # CPU version automatically installed
transformers==4.53.0

# Lightweight incremental ingestion (1-2 videos/day on CPU)
faster-whisper>=1.0.2  # CPU mode works fine for small batches
whisperx>=3.1.1  # Needed for speaker ID
pyannote.audio>=3.1.1  # Needed for diarization
librosa>=0.10.1  # Audio processing
soundfile>=0.12.1  # Audio I/O
yt-dlp>=2023.11.16  # Download new videos

# Utilities
numpy>=1.24.3,<2.0.0
tqdm==4.66.1
isodate==0.6.1
youtube-transcript-api==0.6.1

# Scheduling for automated ingestion
apscheduler==3.10.4

# Note: CPU mode is slow but acceptable for incremental processing:
# - Bulk processing (1200h): Use local GPU machine (~24h)
# - Incremental (1-2 videos/day): Production CPU is fine (~3-5h overnight)
#
# Cost: ~$30/month vs $500+/month for GPU instance
