"""Create segment_embeddings table for multi-model embedding storage

Revision ID: 021
Revises: 020
Create Date: 2025-12-02

This migration introduces a normalized embedding storage system that:
1. Supports multiple embedding models per segment
2. Enables rapid model switching without re-ingestion
3. Provides zero-downtime migration via dual-write strategy
4. Maintains backward compatibility with segments.embedding column

The segment_embeddings table stores embeddings separately from segments,
allowing concurrent storage of embeddings from different models (e.g.,
BGE-small-384, Nomic-768, GTE-Qwen2-1536) for the same segment.

IMPORTANT: The embedding column uses VECTOR(384) - a fixed dimension matching
the active model (bge-small-en-v1.5). This is required for IVFFlat indexing.
If the embedding model changes, a coordinated migration is needed to update
both the column type and rebuild the index.
"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy import text
import os
import json
import logging

logger = logging.getLogger(__name__)

# revision identifiers, used by Alembic.
revision = '021'
down_revision = '020_rag_profiles_auto_select'
branch_labels = None
depends_on = None


def get_active_model_config():
    """Get active embedding model configuration from embedding_models.json"""
    # Try to load from config file
    config_paths = [
        os.path.join(os.path.dirname(__file__), '..', '..', 'config', 'models', 'embedding_models.json'),
        '/app/config/models/embedding_models.json',  # Docker path
    ]
    
    for config_path in config_paths:
        try:
            with open(config_path, 'r') as f:
                config = json.load(f)
                active_model_key = config.get('active_query_model', 'bge-small-en-v1.5')
                models = config.get('models', {})
                if active_model_key in models:
                    model = models[active_model_key]
                    return {
                        'model_key': active_model_key,
                        'dimensions': model.get('dimensions', 384)
                    }
        except (FileNotFoundError, json.JSONDecodeError):
            continue
    
    # Fallback to environment variables
    dimensions = int(os.getenv('EMBEDDING_DIMENSIONS', '384'))
    model_key = os.getenv('EMBEDDING_MODEL_KEY', 'bge-small-en-v1.5')
    
    return {'model_key': model_key, 'dimensions': dimensions}


def upgrade() -> None:
    conn = op.get_bind()
    
    print("=" * 60)
    print("ðŸ”§ Migration 021: Creating segment_embeddings table")
    print("=" * 60)
    
    # Get active model configuration
    model_config = get_active_model_config()
    model_key = model_config['model_key']
    dimensions = model_config['dimensions']
    
    print(f"ðŸ“‹ Active model: {model_key} ({dimensions} dimensions)")
    
    # 1. Check if table already exists (for idempotency)
    result = conn.execute(text("""
        SELECT EXISTS (
            SELECT FROM information_schema.tables 
            WHERE table_schema = 'public' 
            AND table_name = 'segment_embeddings'
        )
    """))
    table_exists = result.scalar()
    
    if table_exists:
        print("\nðŸ“¦ segment_embeddings table already exists, checking structure...")
        # Verify required columns exist
        result = conn.execute(text("""
            SELECT column_name FROM information_schema.columns
            WHERE table_name = 'segment_embeddings'
        """))
        existing_columns = {row[0] for row in result}
        required_columns = {'id', 'segment_id', 'model_key', 'dimensions', 'embedding', 'is_active'}
        
        if required_columns.issubset(existing_columns):
            print("   âœ… Table structure is valid")
        else:
            missing = required_columns - existing_columns
            print(f"   âš ï¸  Missing columns: {missing}")
            print("   Dropping and recreating table...")
            conn.execute(text("DROP TABLE IF EXISTS segment_embeddings CASCADE"))
            table_exists = False
    
    if not table_exists:
        # Create segment_embeddings table
        # Schema design:
        # - UUID primary key for distributed systems compatibility
        # - segment_id FK with CASCADE delete for data integrity
        # - model_key to identify which embedding model was used
        # - dimensions stored for validation and index selection
        # - is_active flag for model switching without data deletion
        # - UNIQUE constraint prevents duplicate embeddings per segment/model
        # - embedding uses VECTOR(384) for IVFFlat index compatibility
        print("\nðŸ“¦ Creating segment_embeddings table...")
        conn.execute(text("""
            CREATE TABLE segment_embeddings (
                id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                segment_id INTEGER NOT NULL REFERENCES segments(id) ON DELETE CASCADE,
                model_key TEXT NOT NULL,
                dimensions INTEGER NOT NULL,
                embedding VECTOR(384) NOT NULL,
                created_at TIMESTAMPTZ NOT NULL DEFAULT now(),
                is_active BOOLEAN NOT NULL DEFAULT TRUE,
                UNIQUE (segment_id, model_key)
            )
        """))
        print("   âœ… Table created")
    else:
        # For existing tables: ensure embedding column has fixed dimensions
        # This ALTER is required for IVFFlat index creation
        print("\nðŸ”§ Ensuring embedding column has fixed dimensions...")
        conn.execute(text("""
            ALTER TABLE segment_embeddings
            ALTER COLUMN embedding TYPE VECTOR(384)
        """))
        print("   âœ… Embedding column type set to VECTOR(384)")
    
    # 2. Create indexes
    print("\nðŸ“Š Creating indexes...")
    
    # Index for model_key + is_active filtering
    conn.execute(text("""
        CREATE INDEX IF NOT EXISTS idx_segment_embeddings_model_active 
        ON segment_embeddings(model_key, is_active) 
        WHERE is_active = TRUE
    """))
    print("   âœ… idx_segment_embeddings_model_active created")
    
    # Index for segment lookups
    conn.execute(text("""
        CREATE INDEX IF NOT EXISTS idx_segment_embeddings_segment_id 
        ON segment_embeddings(segment_id)
    """))
    print("   âœ… idx_segment_embeddings_segment_id created")
    
    # 3. Backfill existing embeddings from segments.embedding
    # This is idempotent due to ON CONFLICT DO NOTHING
    print("\nðŸ“¥ Backfilling embeddings from segments.embedding...")
    
    # Check if there are embeddings to migrate
    result = conn.execute(text("""
        SELECT COUNT(*) as count FROM segments WHERE embedding IS NOT NULL
    """))
    row = result.fetchone()
    total_embeddings = row[0] if row else 0
    
    # Check how many are already migrated
    result = conn.execute(text("""
        SELECT COUNT(*) as count FROM segment_embeddings WHERE model_key = :model_key
    """).bindparams(model_key=model_key))
    row = result.fetchone()
    already_migrated = row[0] if row else 0
    
    if already_migrated >= total_embeddings and total_embeddings > 0:
        print(f"   â„¹ï¸  Already migrated: {already_migrated:,} embeddings (skipping backfill)")
    elif total_embeddings > 0:
        print(f"   Found {total_embeddings:,} embeddings to migrate ({already_migrated:,} already done)")
        
        # Get current embedding dimensions from database
        result = conn.execute(text("""
            SELECT vector_dims(embedding) as dims
            FROM segments
            WHERE embedding IS NOT NULL
            LIMIT 1
        """))
        row = result.fetchone()
        db_dimensions = row[0] if row else dimensions
        
        print(f"   Database embedding dimensions: {db_dimensions}")
        
        # Batch insert to avoid memory issues
        # ON CONFLICT DO NOTHING makes this idempotent for partial runs
        batch_size = 10000
        offset = 0
        migrated = 0
        
        while offset < total_embeddings:
            conn.execute(text("""
                INSERT INTO segment_embeddings (segment_id, model_key, dimensions, embedding, is_active)
                SELECT 
                    id,
                    :model_key,
                    :dimensions,
                    embedding,
                    TRUE
                FROM segments
                WHERE embedding IS NOT NULL
                ORDER BY id
                LIMIT :batch_size OFFSET :offset
                ON CONFLICT (segment_id, model_key) DO NOTHING
            """).bindparams(
                model_key=model_key,
                dimensions=db_dimensions,
                batch_size=batch_size,
                offset=offset
            ))
            
            migrated += batch_size
            offset += batch_size
            print(f"   Migrated {min(migrated, total_embeddings):,}/{total_embeddings:,} embeddings...")
        
        print(f"   âœ… Backfill complete: {total_embeddings:,} embeddings migrated")
    else:
        print("   â„¹ï¸  No existing embeddings to migrate")
    
    # 4. Create IVFFlat vector index for ANN search
    # This index is REQUIRED for performance with 500k+ embeddings
    # The embedding column must be VECTOR(384) for this to work
    print(f"\nðŸ” Creating IVFFlat vector index...")
    
    # Calculate optimal lists parameter based on row count
    # ivfflat lists should be sqrt(n) for optimal performance
    result = conn.execute(text("""
        SELECT COUNT(*) FROM segment_embeddings WHERE model_key = :model_key
    """).bindparams(model_key=model_key))
    row = result.fetchone()
    embedding_count = row[0] if row else 0
    
    import math
    lists = max(10, min(1000, int(math.sqrt(embedding_count)))) if embedding_count > 0 else 100
    
    print(f"   Embedding count: {embedding_count:,}")
    print(f"   Using lists={lists} (sqrt optimization)")
    
    # Create the index - no try/except, we want failures to be visible
    conn.execute(text(f"""
        CREATE INDEX IF NOT EXISTS idx_segment_embeddings_vector
        ON segment_embeddings USING ivfflat (embedding vector_cosine_ops)
        WITH (lists = {lists})
    """))
    print(f"   âœ… IVFFlat index idx_segment_embeddings_vector created")
    
    # 5. Add comment for documentation
    conn.execute(text("""
        COMMENT ON TABLE segment_embeddings IS 
        'Normalized storage for embeddings from multiple models. Supports rapid model switching and concurrent multi-model storage.'
    """))
    
    print("\n" + "=" * 60)
    print("âœ… Migration 021 complete!")
    print("=" * 60)
    print(f"   â€¢ segment_embeddings table with VECTOR(384) column")
    print(f"   â€¢ {total_embeddings:,} embeddings backfilled")
    print(f"   â€¢ IVFFlat index created (lists={lists})")
    print(f"   â€¢ Legacy segments.embedding preserved for fallback")
    print("=" * 60)


def downgrade() -> None:
    conn = op.get_bind()
    
    print("ðŸ”„ Rolling back migration 021...")
    
    # Drop all indexes first
    conn.execute(text("DROP INDEX IF EXISTS idx_segment_embeddings_model_active"))
    conn.execute(text("DROP INDEX IF EXISTS idx_segment_embeddings_segment_id"))
    conn.execute(text("DROP INDEX IF EXISTS idx_segment_embeddings_vector"))
    
    # Drop any legacy model-specific vector indexes (from previous migration versions)
    result = conn.execute(text("""
        SELECT indexname FROM pg_indexes 
        WHERE tablename = 'segment_embeddings' 
        AND indexname LIKE 'idx_se_vector_%'
    """))
    for row in result:
        conn.execute(text(f"DROP INDEX IF EXISTS {row[0]}"))
    
    # Drop the table
    conn.execute(text("DROP TABLE IF EXISTS segment_embeddings CASCADE"))
    
    print("   âœ… segment_embeddings table dropped")
