# Observability Guide

This document explains the logging and observability features in the Dr. Chaffee AI backend.

## Request Tracking

### Request ID (`request_id`)

Every HTTP request is assigned a unique 8-character ID by the `RequestIDMiddleware`.

- **Format**: `req-xxxxxxxx` (e.g., `req-a1b2c3d4`)
- **Source**: Auto-generated on each request
- **Purpose**: Correlate all log lines for a single request

### Session ID (`session_id`)

Optional browser session identifier sent via the `X-Session-ID` header.

- **Format**: 8-character hex string (e.g., `f3e2d1c0`)
- **Source**: Generated by frontend, stored in `localStorage`
- **Purpose**: Track user sessions across multiple requests

### Log Format

All RAG-related logs include a prefix with both IDs:

```
[req=a1b2c3d4 sess=f3e2d1c0] Search: query='carnivore diet' ...
```

If no session ID is provided, it shows as `sess=-`.

## Latency Metrics

The `/search` and `/answer` endpoints log detailed timing breakdowns:

### Search Endpoint

```
[req=xxx sess=yyy] Search: query='...' top_k=100 rerank=true
[req=xxx sess=yyy] SearchDone: results=25 embed_ms=45.2 search_ms=123.4 total_ms=180.5
```

| Metric | Description |
|--------|-------------|
| `embed_ms` | Time to generate query embedding (BGE-small-en-v1.5) |
| `search_ms` | Time for pgvector similarity search |
| `total_ms` | Total request duration |

### Answer Endpoint

```
[req=xxx sess=yyy] Answer: query='...' style=concise top_k=100 clips=20 rerank=true
[req=xxx sess=yyy] AnswerDone: clips=20 candidates=100 embed_ms=42.1 search_ms=98.3 llm_ms=2345.6 total_ms=2500.0 profile=default
```

| Metric | Description |
|--------|-------------|
| `embed_ms` | Query embedding generation |
| `search_ms` | Vector search + optional reranking |
| `llm_ms` | OpenAI API call duration |
| `total_ms` | Total request duration |
| `clips` | Number of clips used in LLM prompt |
| `candidates` | Total candidates from vector search |

## Caching

### Backend Caches

| Cache | TTL | Description |
|-------|-----|-------------|
| Embedding stats | 60s | Database embedding coverage stats |
| Search config | 60s | Search parameters (top_k, reranker, etc.) |
| RAG model catalog | 300s | Available LLM models |
| Embedding model catalog | 300s | Available embedding models |
| Tuning endpoints | 5s | General tuning API responses |

### Frontend Caches

| Cache | TTL | Description |
|-------|-----|-------------|
| Tuning metadata | 30s | RAG models, profiles, search config, instructions |

### Force Refresh

- **Backend**: Add `?refresh=true` query parameter to tuning endpoints
- **Frontend**: Click the refresh button (â†») on tuning dashboard pages

## Debugging Tips

### Correlating Frontend and Backend Logs

1. Open browser DevTools Console
2. Note the session ID logged on page load: `ðŸ” Dr Chaffee AI session: f3e2d1c0`
3. Search backend logs for `sess=f3e2d1c0` to find all requests from that session

### Identifying Slow Requests

1. Look for high `total_ms` values in logs
2. Check which component is slow:
   - High `embed_ms`: Embedding model issue
   - High `search_ms`: Database/pgvector issue
   - High `llm_ms`: OpenAI API latency

### Cache Issues

If data seems stale:
1. Use the refresh button on the tuning dashboard
2. Or add `?refresh=true` to the API URL
3. Backend caches auto-expire after their TTL

## Environment Variables

| Variable | Description |
|----------|-------------|
| `LOG_LEVEL` | Logging verbosity (default: INFO) |
| `DATABASE_URL` | PostgreSQL connection (passwords are masked in logs) |

## DSN Password Masking

Database connection strings are automatically masked in logs:

```
Before: postgresql://user:secret123@host:5432/db
After:  postgresql://user:***@host:5432/db
```

## Daily Summaries

Daily summaries provide LLM-generated usage digests for admin review. They aggregate RAG request data and produce actionable insights about user queries, system performance, and areas for improvement.

### What They Contain

Each daily summary includes:

- **Usage Statistics**: Query counts, answer/search breakdown, distinct sessions, token usage, cost, latency
- **Top Themes**: Common topics users asked about
- **What Worked Well**: Areas where RAG answers were strong
- **Areas for Improvement**: Gaps or confusing responses
- **Error Analysis**: Recurring failure patterns
- **Recommendations**: Concrete suggestions for tuning

**Note**: Summaries do not contain PII. Query text is truncated and aggregated.

### Database Tables

| Table | Purpose |
|-------|---------|
| `rag_requests` | Lightweight request log for aggregation |
| `daily_summaries` | Stored LLM-generated summaries |

### Triggering Generation

#### Via API (Admin Only)

```bash
# Generate for yesterday (default)
curl -X POST http://localhost:8000/api/admin/daily-summaries/generate \
  -H "Content-Type: application/json" \
  -d '{}'

# Generate for specific date
curl -X POST http://localhost:8000/api/admin/daily-summaries/generate \
  -H "Content-Type: application/json" \
  -d '{"summary_date": "2025-12-02"}'

# Force regenerate
curl -X POST http://localhost:8000/api/admin/daily-summaries/generate \
  -H "Content-Type: application/json" \
  -d '{"summary_date": "2025-12-02", "force_regenerate": true}'
```

#### Via CLI Script

```bash
# Generate for yesterday
python -m scripts.generate_daily_summary

# Generate for specific date
python -m scripts.generate_daily_summary --date 2025-12-02

# Force regenerate
python -m scripts.generate_daily_summary --date 2025-12-02 --force

# Dry run (show stats without generating)
python -m scripts.generate_daily_summary --dry-run
```

#### Via Cron (Recommended)

Add to crontab or Coolify scheduled task:

```bash
# Run daily at 2 AM
0 2 * * * cd /app && python -m scripts.generate_daily_summary >> /var/log/daily-summary.log 2>&1
```

### Viewing Summaries

#### Via Frontend

Navigate to `/tuning/summaries` in the tuning dashboard (requires admin auth).

#### Via API

```bash
# List recent summaries
curl http://localhost:8000/api/admin/daily-summaries?limit=7

# Get specific summary
curl http://localhost:8000/api/admin/daily-summaries/2025-12-02
```

### How They Help RAG Tuning

1. **Identify Knowledge Gaps**: See which queries lack good answers
2. **Monitor Quality**: Track success rates and error patterns
3. **Optimize Costs**: Review token usage and cost trends
4. **Guide Custom Instructions**: Summaries suggest specific tuning actions
5. **Track Improvements**: Compare summaries over time to measure impact

### Cost

Daily summary generation uses OpenAI (gpt-4o-mini by default):
- Typical cost: $0.001-0.005 per summary
- Monthly cost for daily generation: ~$0.03-0.15
