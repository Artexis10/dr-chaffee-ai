#!/usr/bin/env python3
"""
Enhanced segments database integration for distil-large-v3 + Chaffee-aware system
Replaces the old chunks-based system with proper speaker attribution
"""

import os
import uuid
import logging
import psycopg2
import psycopg2.extras
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class SegmentsDatabase:
    """Enhanced segments database with speaker attribution and pgvector support"""
    
    @staticmethod
    def _get_segment_value(segment, key, default=None):
        """Helper to get value from either dict or object (handles both TranscriptSegment and dict)"""
        if isinstance(segment, dict):
            return segment.get(key, default)
        else:
            return getattr(segment, key, default)
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        self.connection = None
        
    def get_connection(self):
        """Get database connection"""
        if not self.connection or self.connection.closed:
            self.connection = psycopg2.connect(self.db_url)
        return self.connection
    
    def upsert_source(self, video_id: str, title: str, 
                     source_type: str = 'youtube', 
                     metadata: Optional[Dict] = None,
                     published_at = None,
                     duration_s = None,
                     view_count = None,
                     channel_name = None,
                     channel_url = None,
                     thumbnail_url = None,
                     like_count = None,
                     comment_count = None,
                     description = None,
                     tags = None,
                     url = None) -> int:
        """Upsert video source and return source_id"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                import json
                metadata_json = json.dumps(metadata or {})
                # Pass tags as native Python list for PostgreSQL TEXT[] - psycopg2 handles conversion
                tags_array = tags if tags else None
                
                # Use INSERT ... ON CONFLICT for true upsert
                cur.execute("""
                    INSERT INTO sources (
                        source_type, source_id, title, url, channel_name, channel_url,
                        published_at, duration_s, view_count, like_count, comment_count,
                        description, thumbnail_url, tags, metadata, created_at
                    )
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                    ON CONFLICT (source_type, source_id) DO UPDATE SET
                        title = EXCLUDED.title,
                        url = COALESCE(EXCLUDED.url, sources.url),
                        channel_name = COALESCE(EXCLUDED.channel_name, sources.channel_name),
                        channel_url = COALESCE(EXCLUDED.channel_url, sources.channel_url),
                        published_at = COALESCE(EXCLUDED.published_at, sources.published_at),
                        duration_s = COALESCE(EXCLUDED.duration_s, sources.duration_s),
                        view_count = COALESCE(EXCLUDED.view_count, sources.view_count),
                        like_count = COALESCE(EXCLUDED.like_count, sources.like_count),
                        comment_count = COALESCE(EXCLUDED.comment_count, sources.comment_count),
                        description = COALESCE(EXCLUDED.description, sources.description),
                        thumbnail_url = COALESCE(EXCLUDED.thumbnail_url, sources.thumbnail_url),
                        tags = COALESCE(EXCLUDED.tags, sources.tags),
                        metadata = COALESCE(EXCLUDED.metadata, sources.metadata),
                        updated_at = NOW()
                    RETURNING id
                """, (source_type, video_id, title, url, channel_name, channel_url,
                      published_at, duration_s, view_count, like_count, comment_count,
                      description, thumbnail_url, tags_array, metadata_json, datetime.now()))
                
                source_id = cur.fetchone()[0]
                conn.commit()
                logger.debug(f"Upserted source {video_id} with id {source_id}")
                
                return source_id
                
        except Exception as e:
            logger.error(f"Failed to upsert source {video_id}: {e}")
            if conn:
                conn.rollback()
            raise
    
    def batch_insert_segments(self, segments: List[Dict[str, Any]], 
                            video_id: str,
                            chaffee_only_storage: bool = False,
                            embed_chaffee_only: bool = True) -> int:
        """Batch insert segments with speaker attribution"""
        
        if not segments:
            return 0
        
        # Filter segments if chaffee_only_storage is enabled
        if chaffee_only_storage:
            segments = [seg for seg in segments if self._get_segment_value(seg, 'speaker_label') == 'Chaffee']
            logger.info(f"Chaffee-only storage: filtered to {len(segments)} Chaffee segments")
        
        if not segments:
            logger.info("No segments to insert after filtering")
            return 0
        
        try:
            conn = self.get_connection()
            inserted_count = 0
            
            with conn.cursor() as cur:
                # Prepare batch insert
                insert_query = """
                    INSERT INTO segments (
                        video_id, start_sec, end_sec, speaker_label, speaker_conf,
                        text, avg_logprob, compression_ratio, no_speech_prob,
                        temperature_used, re_asr, is_overlap, needs_refinement,
                        embedding, voice_embedding
                    ) VALUES %s
                """
                
                # Prepare values for batch insert
                values = []
                for segment in segments:
                    # Determine if this segment should get text embedding
                    embedding = None
                    if self._get_segment_value(segment, 'embedding'):
                        speaker_label = self._get_segment_value(segment, 'speaker_label', 'GUEST')
                        # Only embed Chaffee segments if embed_chaffee_only is enabled
                        if not embed_chaffee_only or speaker_label == 'Chaffee':
                            embedding = self._get_segment_value(segment, 'embedding')
                    
                    # Get voice embedding (always store for speaker identification)
                    voice_embedding = self._get_segment_value(segment, 'voice_embedding')
                    
                    # Convert numpy types to Python native types to avoid "schema np does not exist" error
                    def to_native(val):
                        """Convert numpy types to Python native types"""
                        if val is None:
                            return None
                        if hasattr(val, 'item'):  # numpy scalar
                            return val.item()
                        return val
                    
                    def safe_float(val, default=0.0):
                        """Safely convert to float, handling None"""
                        if val is None:
                            return default
                        try:
                            return float(to_native(val))
                        except (ValueError, TypeError):
                            return default
                    
                    # Clamp speaker confidence to [0.0, 1.0] range
                    speaker_conf = to_native(self._get_segment_value(segment, 'speaker_confidence', None))
                    if speaker_conf is not None:
                        speaker_conf = min(1.0, max(0.0, float(speaker_conf)))
                    
                    values.append((
                        video_id,
                        safe_float(self._get_segment_value(segment, 'start', 0.0)),
                        safe_float(self._get_segment_value(segment, 'end', 0.0)),
                        self._get_segment_value(segment, 'speaker_label', 'GUEST'),
                        speaker_conf,
                        self._get_segment_value(segment, 'text', ''),
                        to_native(self._get_segment_value(segment, 'avg_logprob', None)),
                        to_native(self._get_segment_value(segment, 'compression_ratio', None)),
                        to_native(self._get_segment_value(segment, 'no_speech_prob', None)),
                        safe_float(self._get_segment_value(segment, 'temperature_used', 0.0)),
                        bool(self._get_segment_value(segment, 're_asr', False)),
                        bool(self._get_segment_value(segment, 'is_overlap', False)),
                        bool(self._get_segment_value(segment, 'needs_refinement', False)),
                        embedding,
                        voice_embedding
                    ))
                # Execute batch insert
                psycopg2.extras.execute_values(cur, insert_query, values)
                inserted_count = cur.rowcount
                
                conn.commit()
                logger.info(f"Successfully inserted {inserted_count} segments for video {video_id}")
                
                # Classify video type based on speaker distribution
                self._classify_video_type(video_id, segments, conn)
                
            return inserted_count
            
        except Exception as e:
            logger.error(f"Failed to insert segments for {video_id}: {e}")
            if conn:
                conn.rollback()
            raise
    
    def _classify_video_type(self, video_id: str, segments: List[Dict[str, Any]], conn) -> None:
        """Classify video type based on speaker distribution and update all segments."""
        try:
            # Extract speaker labels
            speaker_labels = [
                self._get_segment_value(seg, 'speaker_label') 
                for seg in segments 
                if self._get_segment_value(seg, 'speaker_label')
            ]
            
            if not speaker_labels:
                video_type = 'monologue'  # Default
            else:
                # Calculate speaker statistics
                num_speakers = len(set(speaker_labels))
                guest_count = sum(1 for s in speaker_labels if s == 'GUEST')
                guest_pct = guest_count / len(speaker_labels) if speaker_labels else 0
                
                # Classify based on speaker distribution
                if num_speakers == 1:
                    video_type = 'monologue'
                elif guest_pct > 0.15:
                    video_type = 'interview'
                else:
                    video_type = 'monologue_with_clips'
            
            # Update all segments for this video
            with conn.cursor() as cur:
                cur.execute("""
                    UPDATE segments 
                    SET video_type = %s 
                    WHERE video_id = %s
                """, (video_type, video_id))
                conn.commit()
                
            logger.info(f"Classified video {video_id} as '{video_type}' ({num_speakers} speaker(s), {guest_pct*100:.1f}% guest)")
            
        except Exception as e:
            logger.warning(f"Failed to classify video type for {video_id}: {e}")
            # Don't raise - classification is non-critical
    
    def check_video_exists(self, video_id: str) -> Tuple[Optional[int], int]:
        """Check if video exists and return source_id and segment count"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                # Check if source exists
                cur.execute(
                    "SELECT id FROM sources WHERE source_type = 'youtube' AND source_id = %s",
                    (video_id,)
                )
                result = cur.fetchone()
                
                if not result:
                    return None, 0
                
                source_id = result[0]
                
                # Count existing segments
                cur.execute(
                    "SELECT COUNT(*) FROM segments WHERE video_id = %s",
                    (video_id,)
                )
                segment_count = cur.fetchone()[0]
                
                return source_id, segment_count
                
        except Exception as e:
            logger.error(f"Failed to check video existence for {video_id}: {e}")
            return None, 0
    
    def get_video_stats(self, video_id: str) -> Dict[str, Any]:
        """Get comprehensive video statistics"""
        try:
            conn = self.get_connection()
            with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
                # Get segment statistics
                cur.execute("""
                    SELECT 
                        speaker_label,
                        COUNT(*) as segment_count,
                        SUM(end_sec - start_sec) as total_duration,
                        AVG(speaker_conf) as avg_confidence,
                        COUNT(*) FILTER (WHERE re_asr = true) as refined_count,
                        COUNT(*) FILTER (WHERE embedding IS NOT NULL) as embedded_count
                    FROM segments 
                    WHERE video_id = %s 
                    GROUP BY speaker_label
                """, (video_id,))
                
                speaker_stats = {}
                total_segments = 0
                total_duration = 0.0
                
                for row in cur.fetchall():
                    speaker_label = row['speaker_label']
                    speaker_stats[speaker_label] = {
                        'segment_count': row['segment_count'],
                        'duration': float(row['total_duration'] or 0),
                        'avg_confidence': float(row['avg_confidence'] or 0),
                        'refined_count': row['refined_count'],
                        'embedded_count': row['embedded_count']
                    }
                    total_segments += row['segment_count']
                    total_duration += float(row['total_duration'] or 0)
                
                # Calculate percentages
                for speaker, stats in speaker_stats.items():
                    if total_duration > 0:
                        stats['percentage'] = (stats['duration'] / total_duration) * 100
                    else:
                        stats['percentage'] = 0
                
                return {
                    'video_id': video_id,
                    'total_segments': total_segments,
                    'total_duration': total_duration,
                    'speaker_stats': speaker_stats,
                    'chaffee_percentage': speaker_stats.get('Chaffee', {}).get('percentage', 0)
                }
                
        except Exception as e:
            logger.error(f"Failed to get video stats for {video_id}: {e}")
            return {}
    
    def create_embedding_index(self):
        """Create pgvector index for embeddings (run after bulk loading)"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                logger.info("Creating pgvector index for embeddings...")
                cur.execute("""
                    CREATE INDEX IF NOT EXISTS segments_embedding_idx
                    ON segments USING ivfflat (embedding vector_l2_ops) WITH (lists = 100)
                """)
                conn.commit()
                logger.info("pgvector index created successfully")
                
        except Exception as e:
            logger.error(f"Failed to create embedding index: {e}")
            if conn:
                conn.rollback()
            raise
    
    def cleanup_old_segments(self, video_id: str):
        """Remove existing segments for a video (for re-processing)"""
        try:
            conn = self.get_connection()
            with conn.cursor() as cur:
                cur.execute("DELETE FROM segments WHERE video_id = %s", (video_id,))
                deleted_count = cur.rowcount
                conn.commit()
                
                if deleted_count > 0:
                    logger.info(f"Cleaned up {deleted_count} existing segments for {video_id}")
                
        except Exception as e:
            logger.error(f"Failed to cleanup segments for {video_id}: {e}")
            if conn:
                conn.rollback()
            raise
    
    def close(self):
        """Close database connection"""
        if self.connection and not self.connection.closed:
            self.connection.close()
            self.connection = None
