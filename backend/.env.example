# =============================================================================
# DR. CHAFFEE AI - BACKEND CONFIGURATION
# =============================================================================
# For local development: Copy this file to .env and fill in your actual values
# For production (Coolify): Set these as Environment Variables in the backend app settings
# =============================================================================

# =============================================================================
# DATABASE (Required)
# =============================================================================
# PostgreSQL connection string with pgvector extension
# Local: postgresql://postgres:password@localhost:5432/askdrchaffee
# Production: Set via Coolify environment variables
DATABASE_URL=postgresql://postgres:password@localhost:5432/askdrchaffee

# =============================================================================
# YOUTUBE
# =============================================================================
# YouTube channel to ingest videos from
YOUTUBE_CHANNEL_URL=https://www.youtube.com/@anthonychaffeemd

# Optional: YouTube Data API key for faster video listing
# Leave empty to use yt-dlp instead (slower but no API key needed)
YOUTUBE_API_KEY=

# =============================================================================
# WHISPER ASR (Speech Recognition)
# =============================================================================
# Model: distil-large-v3 (GPU), base (CPU)
WHISPER_MODEL=distil-large-v3

# Compute type: int8_float16 (GPU), int8 (CPU)
WHISPER_COMPUTE=int8_float16

# Device: cuda (GPU), cpu (CPU)
WHISPER_DEVICE=cuda

# Beam size: 5 (GPU), 3 (CPU) - higher = better quality, slower
BEAM_SIZE=5

# Temperature: 0.0 = deterministic, >0 = more creative
TEMPERATURE=0.0

# =============================================================================
# CONCURRENCY (Adjust based on hardware)
# =============================================================================
# GPU: 12, CPU: 4
IO_WORKERS=12

# GPU: 2, CPU: 1
ASR_WORKERS=2

# GPU: 12, CPU: 4
DB_WORKERS=12

# =============================================================================
# SEGMENTATION (For optimal RAG quality)
# =============================================================================
# Minimum characters per segment (good context window)
SEGMENT_MIN_CHARS=1100

# Maximum characters per segment
SEGMENT_MAX_CHARS=1400

# Maximum gap between sentences to merge (seconds)
SEGMENT_MAX_GAP_SECONDS=5.0

# Maximum duration of merged segment (seconds)
SEGMENT_MAX_MERGE_DURATION=120.0

# =============================================================================
# SPEAKER IDENTIFICATION
# =============================================================================
# Enable speaker diarization (separates Chaffee from guests)
ENABLE_SPEAKER_ID=true

# Assume single speaker for faster processing (3x speedup)
ASSUME_MONOLOGUE=true

# Minimum similarity threshold for Chaffee identification
CHAFFEE_MIN_SIM=0.62

# Minimum similarity threshold for guest identification
GUEST_MIN_SIM=0.82

# Clustering threshold for pyannote (lower = more sensitive)
PYANNOTE_CLUSTERING_THRESHOLD=0.3

# =============================================================================
# EMBEDDINGS (Semantic Search)
# =============================================================================
# Profile: 'quality' (GTE-Qwen2-1.5B, 1536-dim) or 'speed' (BGE-Small, 384-dim)
# Default: 'speed' (BGE-Small) - recommended for most deployments
EMBEDDING_PROFILE=speed

# Device: cuda (GPU), cpu (CPU)
# Default: auto-detect (uses CUDA if available, otherwise CPU)
EMBEDDING_DEVICE=cpu

# FORCE_CPU_ONLY: Set to '1' or 'true' to completely disable CUDA
# This is REQUIRED for CPU-only deployments (e.g., Hetzner) where PyTorch
# is not compiled with CUDA support. Prevents "Torch not compiled with CUDA" errors.
# When enabled, torch.cuda.is_available() is monkey-patched to always return False.
FORCE_CPU_ONLY=1

# Explicit dimension override (optional - normally set by profile)
# Only set this if you need to override the profile default
# EMBEDDING_DIMENSIONS=384

# =============================================================================
# ANSWER CACHE (Optional)
# =============================================================================
# Enable semantic caching of AI-generated answers
# When disabled (default), cache lookup/save endpoints are no-ops
# Precedence: env var > embedding_models.json > default (false)
ANSWER_CACHE_ENABLED=false

# =============================================================================
# LOGGING & DEBUG
# =============================================================================
# Enable debug preview of system prompt in logs (default: false)
# When enabled, logs first 1500 chars of system prompt at DEBUG level
LOG_SUMMARIZER_PREVIEW=false

# =============================================================================
# PROCESSING SETTINGS
# =============================================================================
# Skip YouTube Shorts (usually not useful content)
SKIP_SHORTS=true

# Process newest videos first
NEWEST_FIRST=true

# Delete audio files after processing (saves disk space)
CLEANUP_AUDIO_AFTER_PROCESSING=true

# Store audio files permanently (not recommended)
STORE_AUDIO_LOCALLY=false

# =============================================================================
# API KEYS
# =============================================================================
# HuggingFace token for downloading models
HUGGINGFACE_HUB_TOKEN=hf_your_token_here

# OpenAI API key for answer generation (optional)
OPENAI_API_KEY=sk-proj-your_key_here

# Model: gpt-3.5-turbo (cheap), gpt-4o (expensive)
SUMMARIZER_MODEL=gpt-3.5-turbo

# =============================================================================
# AUTHENTICATION (Required in production)
# =============================================================================
# Password for tuning dashboard access
# Set to a secure password - users must enter this to access /tuning
TUNING_PASSWORD=your_secure_tuning_password_here

# Admin API key for protected admin endpoints (upload, sync, jobs)
# MUST be set in production - no insecure default allowed
# Used with: Authorization: Bearer <ADMIN_API_KEY>
# Generate with: openssl rand -base64 32
ADMIN_API_KEY=

# Internal API key for RAG/search endpoint protection
# Prevents direct public access to backend /search, /answer, /embed endpoints
# Frontend Next.js API routes inject this header when proxying requests
# Must match INTERNAL_API_KEY in frontend/.env.local
# Generate with: openssl rand -base64 32
INTERNAL_API_KEY=
